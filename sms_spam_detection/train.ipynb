{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# for data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# for evaluation purposes\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, precision_score, recall_score, classification_report, ConfusionMatrixDisplay, make_scorer\n",
    "\n",
    "# for custom gridsearch\n",
    "from itertools import product\n",
    "\n",
    "# for oversampling\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load Train, Val, Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/train.csv', 'data/val.csv', 'data/test.csv']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train, val, test save_paths\n",
    "\n",
    "data_train_save_path = os.path.join('data','train.csv')\n",
    "data_val_save_path = os.path.join('data','val.csv')\n",
    "data_test_save_path = os.path.join('data','test.csv')\n",
    "\n",
    "train_val_test_save_paths = [data_train_save_path, data_val_save_path, data_test_save_path]\n",
    "\n",
    "train_val_test_save_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_val_test(train_val_test_save_paths, oversampler=None):\n",
    "    # extract the dataframes\n",
    "    train_data = pd.read_csv(train_val_test_save_paths[0])\n",
    "    val_data = pd.read_csv(train_val_test_save_paths[1])\n",
    "    test_data = pd.read_csv(train_val_test_save_paths[2])\n",
    "    \n",
    "    # split the data into features, labels\n",
    "    y_train = train_data['label']\n",
    "    X_train = train_data.drop('label', axis=1)\n",
    "\n",
    "    # oversample the training data\n",
    "    if oversampler:\n",
    "        X_train, y_train = oversampler.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "    y_val = val_data['label']\n",
    "    X_val = val_data.drop('label', axis=1)\n",
    "\n",
    "    y_test = test_data['label']\n",
    "    X_test = test_data.drop('label', axis=1)\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val ,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape: (6530, 8444)\n",
      "Validation Data Shape: (948, 8444)\n",
      "Test Data Shape: (836, 8444)\n"
     ]
    }
   ],
   "source": [
    "# define an oversampler\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val ,y_test = load_train_val_test(train_val_test_save_paths, oversampler=smote)\n",
    "\n",
    "print(\"Training Data Shape:\", X_train.shape)\n",
    "print(\"Validation Data Shape:\", X_val.shape)\n",
    "print(\"Test Data Shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model Fit and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model using GridSearch method from `hypopt` library\n",
    "\n",
    "def train_model(X_train, X_val, y_train, y_val, classifier, param_grid):\n",
    "    \n",
    "    # init best model\n",
    "    best_model = classifier\n",
    "    \n",
    "    # best precision\n",
    "    best_precision = 0.0\n",
    "\n",
    "    # make param_list by considering set products of params\n",
    "    param_list = list(product(*param_grid.values()))\n",
    "\n",
    "    for param in param_list:\n",
    "        param_dict = dict(zip(param_grid.keys(), param))\n",
    "        \n",
    "        # init model with these params\n",
    "        model = classifier.set_params(**param_dict)\n",
    "        # fit the model on train data\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # evaluate the model on val data\n",
    "        y_val_hat = model.predict(X_val)\n",
    "        # calculate precision\n",
    "        current_precision = precision_score(y_val, y_val_hat, average='micro')\n",
    "\n",
    "        # update model, score based on val precision\n",
    "        if current_precision > best_precision:\n",
    "            best_precision = current_precision\n",
    "            best_model = model\n",
    "            \n",
    "            print(\"Current Best Precision on Val: %.3f\" % best_precision)\n",
    "    \n",
    "    # print the best classifier\n",
    "    print(\"Overall Best Model:\", best_model)\n",
    "    print(\"Overall Best Precision on Val: %.3f\" % best_precision)\n",
    "\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 `LogisticRegression`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Best Precision on Val: 0.877\n",
      "Current Best Precision on Val: 0.935\n",
      "Current Best Precision on Val: 0.978\n",
      "Current Best Precision on Val: 0.983\n",
      "Current Best Precision on Val: 0.984\n",
      "Overall Best Model: LogisticRegression(C=10, max_iter=500, solver='liblinear')\n",
      "Overall Best Precision on Val: 0.984\n"
     ]
    }
   ],
   "source": [
    "classifier = LogisticRegression()\n",
    "\n",
    "# define the parameter search space for gridsearch\n",
    "\n",
    "param_grid = {'penalty': ['l1', 'l2'],\n",
    "              'C': [0.001, 0.01, 0.1, 1, 10],\n",
    "              'solver': ['liblinear'],\n",
    "              'max_iter': [100, 200, 500]}\n",
    "\n",
    "best_logit = train_model(\n",
    "                            X_train=X_train,\n",
    "                            X_val=X_val,\n",
    "                            y_train=y_train,\n",
    "                            y_val=y_val,\n",
    "                            classifier=classifier,\n",
    "                            param_grid=param_grid\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best model: `LogisticRegression(C=10, max_iter=500, solver='liblinear')`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 `RandomForestClassifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Best Precision on Val: 0.955\n",
      "Current Best Precision on Val: 0.961\n",
      "Current Best Precision on Val: 0.967\n",
      "Current Best Precision on Val: 0.970\n",
      "Current Best Precision on Val: 0.972\n",
      "Current Best Precision on Val: 0.974\n",
      "Overall Best Model: RandomForestClassifier(max_depth=15, max_features='log2', min_samples_leaf=4,\n",
      "                       min_samples_split=10, n_estimators=200)\n",
      "Overall Best Precision on Val: 0.974\n"
     ]
    }
   ],
   "source": [
    "classifier = RandomForestClassifier()\n",
    "\n",
    "# define the parameter search space for gridsearch\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "best_rfc = train_model(\n",
    "                            X_train=X_train,\n",
    "                            X_val=X_val,\n",
    "                            y_train=y_train,\n",
    "                            y_val=y_val,\n",
    "                            classifier=classifier,\n",
    "                            param_grid=param_grid\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best model: `RandomForestClassifier(max_depth=15, max_features='log2', min_samples_leaf=4, min_samples_split=10, n_estimators=200)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 `GradientBoostingClassifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Best Precision on Val: 0.965\n",
      "Current Best Precision on Val: 0.968\n",
      "Current Best Precision on Val: 0.970\n",
      "Current Best Precision on Val: 0.976\n",
      "Current Best Precision on Val: 0.978\n",
      "Current Best Precision on Val: 0.979\n",
      "Current Best Precision on Val: 0.980\n",
      "Current Best Precision on Val: 0.981\n",
      "Current Best Precision on Val: 0.982\n",
      "Overall Best Model: GradientBoostingClassifier(learning_rate=0.01, loss='exponential', max_depth=5,\n",
      "                           max_features='log2', min_samples_leaf=4,\n",
      "                           min_samples_split=6, n_estimators=500)\n",
      "Overall Best Precision on Val: 0.982\n"
     ]
    }
   ],
   "source": [
    "classifier = GradientBoostingClassifier()\n",
    "\n",
    "# define the parameter search space for gridsearch\n",
    "\n",
    "param_grid = {\n",
    "    'loss': ['log_loss', 'exponential'],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'min_samples_split': [2, 4, 6],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "best_gbc = train_model(\n",
    "                            X_train=X_train,\n",
    "                            X_val=X_val,\n",
    "                            y_train=y_train,\n",
    "                            y_val=y_val,\n",
    "                            classifier=classifier,\n",
    "                            param_grid=param_grid\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best model: `GradientBoostingClassifier(learning_rate=0.01, loss='exponential', max_depth=5, max_features='log2', min_samples_leaf=4, min_samples_split=6, n_estimators=500)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 `AdaBoostClassifier()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Best Precision on Val: 0.900\n",
      "Current Best Precision on Val: 0.949\n",
      "Current Best Precision on Val: 0.975\n",
      "Current Best Precision on Val: 0.978\n",
      "Current Best Precision on Val: 0.981\n",
      "Current Best Precision on Val: 0.983\n",
      "Overall Best Model: AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=3),\n",
      "                   n_estimators=200)\n",
      "Overall Best Precision on Val: 0.983\n"
     ]
    }
   ],
   "source": [
    "# to suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "classifier = AdaBoostClassifier()\n",
    "\n",
    "# define the parameter search space for gridsearch\n",
    "\n",
    "param_grid = {'base_estimator': [DecisionTreeClassifier(max_depth=1), DecisionTreeClassifier(max_depth=2), DecisionTreeClassifier(max_depth=3)],\n",
    "              'n_estimators': [50, 100, 200],\n",
    "              'learning_rate': [0.1, 0.5, 1.0],\n",
    "              'algorithm': ['SAMME', 'SAMME.R']\n",
    "             }\n",
    "\n",
    "best_abc = train_model(\n",
    "                            X_train=X_train,\n",
    "                            X_val=X_val,\n",
    "                            y_train=y_train,\n",
    "                            y_val=y_val,\n",
    "                            classifier=classifier,\n",
    "                            param_grid=param_grid\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best model: `AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=3), n_estimators=200)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('mlenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40924fa2106280d40699e6c83945076296c5ea7479ac09c70297abf04386ebf0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
